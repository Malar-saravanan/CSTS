{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbP4kNyA33yw"
      },
      "source": [
        "# Run this in Google Colab\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/morriswong/hungrydata/blob/main/llm_with_search.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "EpUZwwuX33yy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -qU langchain-groq\n",
        "%pip install -qU langchain\n",
        "%pip install -qU langchain-community\n",
        "%pip install -qU duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "YgCN4cVA33yy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = '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'\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJBp1d_A33yz",
        "outputId": "63c272b5-cd2f-4422-de10-95e7098f5581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-36ae0ca615a1>:15: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain_community.tools import Tool, DuckDuckGoSearchRun, DuckDuckGoSearchResults\n",
        "from langchain.agents import Tool\n",
        "\n",
        "ddg_search = DuckDuckGoSearchResults()\n",
        "\n",
        "tools = [\n",
        "   Tool(\n",
        "       name=\"DuckDuckGo Search\",\n",
        "       func=ddg_search.run,\n",
        "       description=\"Useful to browse information from the Internet.\",\n",
        "   )\n",
        "]\n",
        "\n",
        "agent = initialize_agent(\n",
        "   tools, llm, agent=\"zero-shot-react-description\", verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "aCOYodeI33yz",
        "outputId": "9206728a-b56c-40f2-8caa-6c732f5dd966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the top 10 competitors of Frooti, I need to search the internet for a list of companies that compete with Frooti in the beverage industry. I will use the DuckDuckGo Search tool for this.\n",
            "\n",
            "Action: DuckDuckGo Search\n",
            "Action Input: \"top 10 competitors of Frooti\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3msnippet: Parle Agro has 83 competitors. Parle Agro - Brand of multi-category beverages. Raised funding from 1 investor. ... Brand of multi-category beverages. It offers a wide range of brands, including Frooti, Appy Fizz, LMN, Hippo, Bailley, Dhishoom, Bombay 99, and Smoodh. ... Here is the list of Top 10 competitors of Parle Agro, ranked by Tracxn ..., title: Parle Agro - Company Profile - Tracxn, link: https://tracxn.com/d/companies/parle-agro/__DSW2dmVOrvajz_qa1Tt7-uqKLoTJMV1yATV2NGKN4IA, snippet: Their competitors include brands like slice and Frooti. Product Features-This holds 1.2 L of the beverage. It is mango-flavored. ... The top 10 soft drink brands in India include Coca-Cola, Pepsi, Thums Up, Sprite, Limca, Fanta, Mountain Dew, Mirinda, 7 Up, and PepsiCo's Aquafina. ..., title: Top 10 Soft Drink Brands in India | Refreshing Choices 2024, link: https://www.mishry.com/top-10-soft-drink-brands-india/, snippet: Here is the list of Top 10 competitors of Mango Frooti, ranked by Tracxn score : Overall Rank. Company Details. Short Description. Total Funding. Investors. Tracxn Score. 1st. Raw Pressery. 2013, Mumbai , Acquired. Brand of cold-pressed juices. $32.8M. Sequoia Capital, Innoven Capital & ..., title: Mango Frooti - Company Profile - Tracxn, link: https://tracxn.com/d/companies/mango-frooti/__LF_hqF9kOCPZmmCBoP7nYZmbPFcGAcujfc6Ghf03dFg, snippet: Here's an overview of Frooti's price strategy: Value-Based Pricing: Frooti adopts a value-based pricing approach, aligning its prices with the perceived value consumers associate with its premium-quality mango drink. This strategy allows Frooti to position itself as a desirable and indulgent choice among consumers seeking a refreshing fruit beverage., title: Marketing Mix of Frooti and 4Ps (Updated 2025) | Marketing91, link: https://www.marketing91.com/marketing-mix-frooti/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, I can see that the top 10 competitors of Frooti include both direct competitors in the mango-flavored beverage segment and broader competitors in the soft drink industry. Some of the direct competitors include Slice and Raw Pressery. The broader competitors in the soft drink industry include Coca-Cola, Pepsi, Thums Up, Sprite, Limca, Fanta, Mountain Dew, Mirinda, 7 Up, and PepsiCo's Aquafina.\n",
            "\n",
            "Final Answer: The top 10 competitors of Frooti include Slice, Raw Pressery, Coca-Cola, Pepsi, Thums Up, Sprite, Limca, Fanta, Mountain Dew, Mirinda, and Aquafina.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The top 10 competitors of Frooti include Slice, Raw Pressery, Coca-Cola, Pepsi, Thums Up, Sprite, Limca, Fanta, Mountain Dew, Mirinda, and Aquafina.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "agent = initialize_agent(\n",
        "   tools, llm, agent=\"zero-shot-react-description\", verbose=True\n",
        ")\n",
        "\n",
        "agent.run(\n",
        "   \"top 10 competitors  of frooti\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools import DuckDuckGoSearchResults, Tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "from typing import Dict, List, Annotated, Sequence, TypedDict, Union\n",
        "import operator\n",
        "import json\n",
        "from langchain_core.tools import Tool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = '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'\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "# Initialize DuckDuckGo search tool\n",
        "ddg_search = DuckDuckGoSearchResults(name=\"duckduckgo_results_json\")\n",
        "\n",
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"The search query string\")\n",
        "\n",
        "def duckduckgo_search_run(query: str):\n",
        "    return ddg_search.run(query)\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"duckduckgo_results_json\",\n",
        "        func=duckduckgo_search_run,\n",
        "        description=\"Useful to search the internet for information. Input to this tool is a search query.\",\n",
        "        args_schema=SearchInput,\n",
        "    )\n",
        "]\n",
        "\n",
        "# Convert tools to OpenAI function format\n",
        "functions = [convert_to_openai_function(t) for t in tools]\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[Union[HumanMessage, AIMessage]], operator.add]\n",
        "    next: str\n",
        "\n",
        "def should_continue(state: AgentState):\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
        "        return \"call_tool\"\n",
        "    else:\n",
        "        return \"generate_response\"\n",
        "\n",
        "def call_tool(state: AgentState):\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    tool_calls = last_message.tool_calls\n",
        "    tool_name = tool_calls[0].name\n",
        "    tool_input = json.loads(tool_calls[0].args)\n",
        "\n",
        "    for tool in tools:\n",
        "        if tool.name == tool_name:\n",
        "            tool_output = tool.func(**tool_input)\n",
        "            messages.append(AIMessage(content=\"\", tool_calls=tool_calls))\n",
        "            messages.append(HumanMessage(content=str(tool_output), name=tool_name))\n",
        "            return {\"messages\": messages, \"next\": \"continue\"}\n",
        "\n",
        "    return {\"messages\": messages, \"next\": \"continue\"}\n",
        "\n",
        "def generate_response(state: AgentState):\n",
        "    messages = state['messages']\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": messages + [response], \"next\": \"end\"}\n",
        "\n",
        "def create_agent_workflow():\n",
        "    workflow = StateGraph(AgentState)\n",
        "    workflow.add_node(\"agent\", lambda state: {\"messages\": state['messages'] + [llm.invoke(state['messages'], functions=functions)], \"next\": should_continue(state)})\n",
        "    workflow.add_node(\"call_tool\", call_tool)\n",
        "    workflow.add_node(\"generate_response\", generate_response)\n",
        "\n",
        "    def route(state):\n",
        "        next_step = state['next']\n",
        "        return next_step\n",
        "\n",
        "    workflow.add_node(\"route\", route)\n",
        "    workflow.add_edge(\"agent\", \"route\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"route\",\n",
        "        lambda state: state,\n",
        "        {\n",
        "            \"call_tool\": \"call_tool\",\n",
        "            \"generate_response\": \"generate_response\"\n",
        "        }\n",
        "    )\n",
        "    workflow.add_edge(\"call_tool\", \"agent\")\n",
        "    workflow.add_edge(\"generate_response\", END)\n",
        "    workflow.set_entry_point(\"agent\")\n",
        "    return workflow.compile()\n",
        "\n",
        "agent_workflow = create_agent_workflow()\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"Use the search tool to find the weather in London for the next 3 days.\")]}\n",
        "\n",
        "for output in agent_workflow.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        print(f\"Node '{key}':\")\n",
        "        print(value)\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "id": "azlZUYgF4nO-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}